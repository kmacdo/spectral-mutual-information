{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0b51a14acff7a1d5bb3f2b517db7519a8b451c2d30ff1033b03fd9708e914f209",
   "display_name": "Python 3.9.4 64-bit ('SMI': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "b51a14acff7a1d5bb3f2b517db7519a8b451c2d30ff1033b03fd9708e914f209"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matrix_method as matrix_method"
   ]
  },
  {
   "source": [
    "# Short Description of the Method\n",
    "The canonical definition of Mutual Information is \n",
    "$$ \n",
    "I(X;Y) = - \\sum_{x,y} P_{X,Y}(x,y) \\log \\frac{P_{X,Y}(x,y)}{P_X(x)P_Y(y)}\n",
    "$$\n",
    "where $P_{X,Y}$ is the joint distribution, and $P_X, P_Y$ are the marginals.\n",
    "\n",
    "But mutual information has many equivalent definitions involving the entropy. When using Von Neumann entropy, the most convenient is\n",
    "$$\n",
    "I(X,Y) = H(X) + H(Y) - H(X,Y)\n",
    "$$\n",
    "where $H(X)$ is the entropy of $X$, and $H(X,Y)$ is the joint entropy of $X$ and $Y$.\n",
    "\n",
    "Von Neumann entropy was defined over the density matrix $\\rho$ of a quantum state. It works by casting the matrix into the spectral domain and computing the entropy of its eigenvalues. \n",
    "$$ S(X) = - \\sum_i \\eta_i \\log \\eta_i $$\n",
    "@Passerini2021 describes a map between the density matrix and the normalized graph laplacian. Specifically, the Laplacian $L = D - A$ is computed, and divided by the (scalar) trace of $D$.\n",
    "\n",
    "So, with the background behind us -\n",
    "\n",
    "Given two matrices X and Y (which can contain different numbers of points, but currently must contain points in the same dimension):\n",
    "1. Computes a graph from X and Y, and `concat(X,Y)`.\n",
    "2. Gets the normalized laplacian of each graph\n",
    "3. Calculates the entropy from each graph, and\n",
    "4. Returns the mutual information $I(x,y) = H(X) + H(Y) - H(X,Y)$.\n",
    "\n",
    "Here's an example computation between two random matrices. This uses the graphtools backend to compute a knn graph, with k=10."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A matrix from sklearn [[0. 0. 0. ... 0. 1. 1.]\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 1. 0. 1.]\n ...\n [0. 0. 1. ... 0. 0. 0.]\n [1. 0. 1. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]]\ntotal degree sum 200.0\nRho matrix [[ 0.025  0.     0.    ...  0.    -0.005 -0.005]\n [ 0.     0.025  0.    ...  0.     0.    -0.005]\n [ 0.     0.     0.025 ... -0.005  0.    -0.005]\n ...\n [ 0.     0.    -0.005 ...  0.025  0.     0.   ]\n [-0.005  0.    -0.005 ...  0.     0.025  0.   ]\n [ 0.     0.    -0.005 ...  0.     0.     0.025]]\nevals [0.00201904 0.00270899 0.00444318 0.00857495 0.00958492 0.01118882\n 0.01221174 0.01229411 0.01696092 0.01741246 0.01780107 0.01907709\n 0.02043197 0.02251095 0.02328043 0.02384419 0.02403422 0.02465926\n 0.02639737 0.02681432 0.02773603 0.02801271 0.02906734 0.02941753\n 0.03044031 0.03139203 0.03192282 0.03255479 0.03304776 0.03320132\n 0.03360654 0.03435386 0.0349876  0.0358253  0.03655945 0.03742659\n 0.03797023 0.0390694  0.03983098 0.04136548]\nA matrix from sklearn [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]]\ntotal degree sum 200.0\nRho matrix [[ 0.025  0.     0.    ...  0.     0.     0.   ]\n [ 0.     0.025  0.    ...  0.     0.     0.   ]\n [ 0.     0.     0.025 ...  0.     0.    -0.005]\n ...\n [ 0.     0.     0.    ...  0.025  0.     0.   ]\n [ 0.     0.     0.    ...  0.     0.025  0.   ]\n [ 0.     0.    -0.005 ...  0.     0.     0.025]]\nevals [0.00139484 0.00373475 0.00443357 0.00726097 0.00938771 0.01123842\n 0.0124241  0.01486102 0.01666574 0.01777725 0.01864968 0.0191644\n 0.02070409 0.02156203 0.02256636 0.023569   0.02418168 0.02490908\n 0.02535216 0.0265672  0.02793402 0.02821467 0.02854998 0.02968281\n 0.03050448 0.03095515 0.03168456 0.03226309 0.03251933 0.03354419\n 0.0343118  0.03489708 0.03531983 0.03638162 0.03684443 0.03724728\n 0.03779935 0.03840277 0.03892295 0.04040621]\nusing double neighbors\nA matrix from sklearn [[0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 1. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]]\ntotal degree sum 800.0\nRho matrix [[ 0.0125   0.       0.      ...  0.       0.      -0.00125]\n [ 0.       0.0125   0.      ...  0.      -0.00125  0.     ]\n [ 0.       0.       0.0125  ...  0.       0.       0.     ]\n ...\n [ 0.       0.       0.      ...  0.0125   0.       0.     ]\n [ 0.      -0.00125  0.      ...  0.       0.0125   0.     ]\n [-0.00125  0.       0.      ...  0.       0.       0.0125 ]]\nevals [0.00017503 0.00224367 0.00283335 0.00363998 0.00442092 0.00532789\n 0.00598208 0.0062587  0.00727168 0.00778808 0.0083161  0.00858005\n 0.00871255 0.00890199 0.00929747 0.00970099 0.00984492 0.01028899\n 0.01047332 0.0105231  0.01077558 0.01091761 0.0110516  0.01115835\n 0.01139176 0.01159672 0.01170505 0.01186937 0.01191179 0.01214405\n 0.01230278 0.0125693  0.01266766 0.01277445 0.0128299  0.01300781\n 0.01312094 0.01326893 0.01330575 0.01345139 0.01355197 0.01364465\n 0.0137005  0.01372375 0.01376152 0.0138606  0.01388699 0.01407418\n 0.01428237 0.01435143 0.0144324  0.01447241 0.01460906 0.01475598\n 0.01478087 0.01489925 0.01502406 0.01505089 0.01514857 0.01527264\n 0.01541009 0.01544046 0.01556334 0.01562141 0.01578909 0.01585493\n 0.01603246 0.01621718 0.01634401 0.01641375 0.01645451 0.01651211\n 0.01672559 0.01676706 0.01684335 0.0169544  0.01718911 0.01736948\n 0.01742251 0.01773951]\nHX 3.588090215970679 + HY  3.586164665539424  - HXY  4.323556498906703\nMutual info 2.850698382603401\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(40,5)\n",
    "Y = np.random.rand(40,5)\n",
    "a = matrix_method.spectral_mutual_information(X,Y)\n",
    "print(f\"Mutual info {a}\")"
   ]
  },
  {
   "source": [
    "As a sanity check, the mutual information should be much higher when $X = Y$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A matrix from sklearn [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 1. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\ntotal degree sum 200.0\nRho matrix [[ 0.025  0.     0.    ...  0.     0.     0.   ]\n [ 0.     0.025  0.    ...  0.     0.     0.   ]\n [ 0.     0.     0.025 ...  0.    -0.005  0.   ]\n ...\n [ 0.     0.     0.    ...  0.025  0.     0.   ]\n [ 0.     0.     0.    ...  0.     0.025  0.   ]\n [ 0.     0.     0.    ...  0.     0.     0.025]]\nevals [0.00404828 0.00020616 0.00321572 0.00573291 0.00749887 0.01315717\n 0.01350815 0.01532833 0.0168744  0.01780947 0.0183872  0.02035297\n 0.02106554 0.02195156 0.02431966 0.02477468 0.025      0.02551626\n 0.02624371 0.02762933 0.02843333 0.02890681 0.03       0.03\n 0.03020142 0.03102244 0.03186361 0.03219402 0.03229119 0.03308293\n 0.03396032 0.03463309 0.03482498 0.03579037 0.03633596 0.03695779\n 0.0378361  0.0382874  0.03892843 0.04033831]\nA matrix from sklearn [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 1. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\ntotal degree sum 200.0\nRho matrix [[ 0.025  0.     0.    ...  0.     0.     0.   ]\n [ 0.     0.025  0.    ...  0.     0.     0.   ]\n [ 0.     0.     0.025 ...  0.    -0.005  0.   ]\n ...\n [ 0.     0.     0.    ...  0.025  0.     0.   ]\n [ 0.     0.     0.    ...  0.     0.025  0.   ]\n [ 0.     0.     0.    ...  0.     0.     0.025]]\nevals [0.00404828 0.00020616 0.00321572 0.00573291 0.00749887 0.01315717\n 0.01350815 0.01532833 0.0168744  0.01780947 0.0183872  0.02035297\n 0.02106554 0.02195156 0.02431966 0.02477468 0.025      0.02551626\n 0.02624371 0.02762933 0.02843333 0.02890681 0.03       0.03\n 0.03020142 0.03102244 0.03186361 0.03219402 0.03229119 0.03308293\n 0.03396032 0.03463309 0.03482498 0.03579037 0.03633596 0.03695779\n 0.0378361  0.0382874  0.03892843 0.04033831]\nA matrix from sklearn [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 1. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\ntotal degree sum 800.0\nRho matrix [[ 0.0125   0.       0.      ...  0.       0.       0.     ]\n [ 0.       0.0125   0.      ...  0.       0.       0.     ]\n [ 0.       0.       0.0125  ...  0.      -0.00125  0.     ]\n ...\n [ 0.       0.       0.      ...  0.0125   0.       0.     ]\n [ 0.       0.       0.      ...  0.       0.0125   0.     ]\n [ 0.       0.       0.      ...  0.       0.       0.0125 ]]\nevals [0.00143291 0.00025896 0.00104059 0.00292189 0.00306174 0.00546014\n 0.00598606 0.00632128 0.00728188 0.00774873 0.00797841 0.00888751\n 0.00942466 0.00971493 0.01005091 0.01032743 0.0108939  0.01104743\n 0.01135021 0.01148764 0.01154304 0.01178183 0.01183989 0.01205453\n 0.01213254 0.01229648 0.01241325 0.01251885 0.01257181 0.01272\n 0.01294467 0.01298344 0.01303377 0.01305912 0.01325947 0.01329594\n 0.01334444 0.01344796 0.01349784 0.01355165 0.01359162 0.0136904\n 0.01375    0.01375    0.01375    0.01381566 0.01386067 0.01390687\n 0.0139373  0.01400399 0.01410933 0.01419033 0.01421169 0.01434195\n 0.01440384 0.01446241 0.01454611 0.01457059 0.01463081 0.01481373\n 0.01498867 0.01511045 0.01525535 0.01527006 0.01529305 0.01551034\n 0.0155707  0.01559825 0.0159018  0.01595938 0.01603194 0.01611174\n 0.01636604 0.01665496 0.01677004 0.01708745 0.01727975 0.01743976\n 0.01762742 0.01825156]\nHX 3.5950093843543174 + HY  3.5950093843543174  - HXY  4.330123947217696\nMutual info 2.859894821490939\n"
     ]
    }
   ],
   "source": [
    "a = matrix_method.spectral_mutual_information(X,X)\n",
    "print(f\"Mutual info {a}\")"
   ]
  },
  {
   "source": [
    "It doesn't do *much* better.\n",
    "\n",
    "This seems to be an artifact of the KNN graph construction. In the case where X=Y, each point should have an additional neighbor with zero distance.\n",
    "Perhaps computation through the affinity matrix does better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adjacency [[0.         0.0894966  0.16786662 ... 0.22603731 0.26477877 0.1659443 ]\n [0.0894966  0.         0.2567415  ... 0.09208004 0.39990861 0.41927736]\n [0.16786662 0.2567415  0.         ... 0.05018176 0.28066441 0.8046731 ]\n ...\n [0.22603731 0.09208004 0.05018176 ... 0.         0.11386363 0.12357096]\n [0.26477877 0.39990861 0.28066441 ... 0.11386363 0.         0.35297928]\n [0.1659443  0.41927736 0.8046731  ... 0.12357096 0.35297928 0.        ]]\nadjacency [[0.         0.11785122 0.30179518 ... 0.0953715  0.15973888 0.77703644]\n [0.11785122 0.         0.16471074 ... 0.23339387 0.6185102  0.1872688 ]\n [0.30179518 0.16471074 0.         ... 0.32472097 0.43521061 0.29139477]\n ...\n [0.0953715  0.23339387 0.32472097 ... 0.         0.69815066 0.24257109]\n [0.15973888 0.6185102  0.43521061 ... 0.69815066 0.         0.310577  ]\n [0.77703644 0.1872688  0.29139477 ... 0.24257109 0.310577   0.        ]]\nadjacency [[0.         0.0894966  0.16786662 ... 0.24918544 0.24769863 0.16956836]\n [0.0894966  0.         0.2567415  ... 0.21507768 0.37764853 0.84881624]\n [0.16786662 0.2567415  0.         ... 0.04544289 0.09965721 0.34038672]\n ...\n [0.24918544 0.21507768 0.04544289 ... 0.         0.69815066 0.24257109]\n [0.24769863 0.37764853 0.09965721 ... 0.69815066 0.         0.310577  ]\n [0.16956836 0.84881624 0.34038672 ... 0.24257109 0.310577   0.        ]]\nHX 3.617472382990093 + HY  3.6213352077339014  - HXY  4.332310581690666\nMutual info 2.9064970090333286\n"
     ]
    }
   ],
   "source": [
    "a = matrix_method.spectral_mutual_information_via_affinity(X,Y)\n",
    "print(f\"Mutual info {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adjacency [[0.         0.0894966  0.16786662 ... 0.22603731 0.26477877 0.1659443 ]\n [0.0894966  0.         0.2567415  ... 0.09208004 0.39990861 0.41927736]\n [0.16786662 0.2567415  0.         ... 0.05018176 0.28066441 0.8046731 ]\n ...\n [0.22603731 0.09208004 0.05018176 ... 0.         0.11386363 0.12357096]\n [0.26477877 0.39990861 0.28066441 ... 0.11386363 0.         0.35297928]\n [0.1659443  0.41927736 0.8046731  ... 0.12357096 0.35297928 0.        ]]\nadjacency [[0.         0.0894966  0.16786662 ... 0.22603731 0.26477877 0.1659443 ]\n [0.0894966  0.         0.2567415  ... 0.09208004 0.39990861 0.41927736]\n [0.16786662 0.2567415  0.         ... 0.05018176 0.28066441 0.8046731 ]\n ...\n [0.22603731 0.09208004 0.05018176 ... 0.         0.11386363 0.12357096]\n [0.26477877 0.39990861 0.28066441 ... 0.11386363 0.         0.35297928]\n [0.1659443  0.41927736 0.8046731  ... 0.12357096 0.35297928 0.        ]]\nadjacency [[0.         0.0894966  0.16786662 ... 0.22603731 0.26477877 0.1659443 ]\n [0.0894966  0.         0.2567415  ... 0.09208004 0.39990861 0.41927736]\n [0.16786662 0.2567415  0.         ... 0.05018176 0.28066441 0.8046731 ]\n ...\n [0.22603731 0.09208004 0.05018176 ... 0.         0.11386363 0.12357096]\n [0.26477877 0.39990861 0.28066441 ... 0.11386363 0.         0.35297928]\n [0.1659443  0.41927736 0.8046731  ... 0.12357096 0.35297928 0.        ]]\nHX 3.617472382990093 + HY  3.617472382990093  - HXY  4.3306586798892415\nMutual info 2.904286086090945\n"
     ]
    }
   ],
   "source": [
    "a = matrix_method.spectral_mutual_information_via_affinity(X,X)\n",
    "print(f\"Mutual info {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating the laplacian. How am I getting such big eigenvalues?\n"
   ]
  }
 ]
}